{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "099pLRwh-Z2K",
        "outputId": "69a2d387-5dee-4bb4-a133-35f3f182d30c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.23.1-py3-none-any.whl (5.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.3 MB 33.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 87.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (5.0.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 82.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.9.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.10.1 tokenizers-0.13.1 transformers-4.23.1\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8QLOUpUe_38d"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import copy\n",
        "import glob\n",
        "import math\n",
        "from scipy import io\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import OrderedDict\n",
        "\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModel, BertTokenizer, BertModel\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "from google.colab import drive\n",
        "import tensorflow as tf\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.utils import shuffle\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4dypnCF_6iu",
        "outputId": "75e09ba1-8042-4ed3-b67b-5b5f1a444740"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "#define device for deep learning\n",
        "CUDA_LAUNCH_BLOCKING=1\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name == '/device:GPU:0':\n",
        "    device = torch.device(\"cuda\")\n",
        "    print('GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7X-80kJKAHiz",
        "outputId": "f582436f-8e92-4cac-ef33-8d6ed44f5df3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# set environment as googledrive to folder \"resource\"\n",
        "data_path =  \"/Colab Notebooks/\"\n",
        "\n",
        "try:\n",
        "    drive.mount('/content/drive')\n",
        "    data_path = \"/content/drive/MyDrive/Colab Notebooks/alta/\"\n",
        "\n",
        "except:\n",
        "    print(\"You are not working in Colab at the moment :(\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u8Lv4XQcANXf"
      },
      "outputs": [],
      "source": [
        "bert_model = \"allenai/scibert_scivocab_cased\" #\"bert-base-multilingual-cased\"\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "torch.cuda.manual_seed_all(RANDOM_SEED)\n",
        "\n",
        "num_classes = 5\n",
        "hidden = 100\n",
        "batch_size = 16\n",
        "epoch_size = 10\n",
        "learning_rate = 2e-5\n",
        "patience_all = 20\n",
        "init_weight_decay = 0.1\n",
        "\n",
        "max_length = 100\n",
        "dropout = 0.1\n",
        "\n",
        "# Transformer parameters\n",
        "d_model = 1\n",
        "n_layers = 1\n",
        "n_hidden = 1\n",
        "heads = 1\n",
        "\n",
        "freeze_bert = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vsaB9l82Al-y"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, df, tokenizer, max_length):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_length\n",
        "        self.text = df[\"Text\"]\n",
        "        self.targets = df[\"target_list\"]\n",
        "        self.id_list = df[\"Document\"]\n",
        "        self.sentence_id_list = df[\"Sentence\"]\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      selected_text = self.text.iloc[idx]\n",
        "      selected_id = self.id_list.iloc[idx]\n",
        "      selected_id_text = self.sentence_id_list.iloc[idx]\n",
        "      inputs = self.tokenizer.encode_plus(\n",
        "          selected_text ,\n",
        "          None,\n",
        "          add_special_tokens=True,\n",
        "          max_length=self.max_len,\n",
        "          padding='max_length',\n",
        "          return_token_type_ids=True,\n",
        "          truncation=True,\n",
        "          return_attention_mask=True,\n",
        "      )\n",
        "      \n",
        "      tokens = torch.tensor(inputs[\"input_ids\"], dtype=torch.long)\n",
        "      token_type_ids = torch.tensor(inputs[\"token_type_ids\"], dtype=torch.long)\n",
        "      attn_mask = torch.tensor(inputs[\"attention_mask\"], dtype=torch.long)\n",
        "\n",
        "\n",
        "      selected_label = torch.FloatTensor(self.targets.iloc[idx])\n",
        "      return tokens, token_type_ids, attn_mask, selected_label, selected_text, selected_id, selected_id_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6y0mwD9DLfV"
      },
      "outputs": [],
      "source": [
        "class TransformerTextModel(nn.Module):\n",
        "    def __init__(self, embedding, ninp, nhead, nhid, nlayers, nout=6, dropout=0.5):\n",
        "        super(TransformerTextModel, self).__init__()\n",
        "        self.nhid = nhid\n",
        "        \n",
        "        self.bert = embedding\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.pos_encoder = PositionalEncodingText(ninp, dropout)\n",
        "        encoder_layers = TransformerEncoderLayer(ninp, nhead, nhid, dropout)\n",
        "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
        "\n",
        "        self.decoder = nn.Linear(ninp*2, nout)\n",
        "\n",
        "            \n",
        "    def generate_square_subsequent_mask(self, sz):\n",
        "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0,1)\n",
        "        mask = mask.float().mask_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "        return mask\n",
        "    \n",
        "\n",
        "    def forward(self, input_ids, token_type_ids, attn_mask):\n",
        "        src = self.bert(input_ids, token_type_ids, attn_mask)\n",
        "        bert = src.hidden_states[-1][:,0,:]\n",
        "        src = src[0]\n",
        "        \n",
        "        src = self.dropout(src)\n",
        "        src = src * math.sqrt(self.nhid)\n",
        "        src = self.pos_encoder(src)\n",
        "        output = self.transformer_encoder(src)\n",
        "        output =  torch.cat((bert, output), dim=1)\n",
        "        output = self.decoder(output)\n",
        "        return output\n",
        "\n",
        "\n",
        "class PositionalEncodingText(nn.Module):\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncodingText, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('pe', pe)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:x.size(0), :]\n",
        "        return self.dropout(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpYU055YDWDm"
      },
      "outputs": [],
      "source": [
        "def save_checkpoint(state, location):\n",
        "  \"\"\"save the models\n",
        "  input:\n",
        "  state : dict (the parameters of the model will be saved)\n",
        "  file_path : string (the path wehere the model will be saved)\n",
        "  \"\"\"\n",
        "  filepath = os.path.join(location, 'best.pth.tar')\n",
        "  torch.save(state, filepath)\n",
        "\n",
        "def load_checkpoint(location):\n",
        "  \"\"\"save the models\n",
        "  input:\n",
        "  file_path : string (the path where the model will be saved)\n",
        "  output:\n",
        "  model : torch nn.Module (the loaded model)\n",
        "  \"\"\"\n",
        "  model = torch.load(location)\n",
        "  return model\n",
        "\n",
        "\n",
        "def train(train_dl):\n",
        "  model.train()\n",
        "  total_loss = 0.\n",
        "  for batch in train_dl:\n",
        "    optimizer.zero_grad()\n",
        "    tokens, token_type_ids, attn_mask, label, selected_text, selected_id, selected_id_text = batch\n",
        "    label = label.to(device)\n",
        "    tokens, token_type_ids, attn_mask = tokens.to(device), token_type_ids.to(device), attn_mask.to(device)\n",
        "    output = model(tokens, attn_mask, token_type_ids)\n",
        "    loss = criterion(output, label)\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "    \n",
        "    optimizer.step()\n",
        "    \n",
        "    total_loss += loss.item() \n",
        "\n",
        "  return total_loss / len(train_dl) \n",
        "\n",
        "\n",
        "def evaluate(model, dl):\n",
        "  total_loss = 0.\n",
        "  prediction_list = []\n",
        "  label_list = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    model.eval()\n",
        "    for batch in dl:\n",
        "      tokens, token_type_ids, attn_mask, label, selected_text, selected_id, selected_id_text = batch\n",
        "\n",
        "      label = label.to(device)\n",
        "      tokens, token_type_ids, attn_mask = tokens.to(device), token_type_ids.to(device), attn_mask.to(device)\n",
        "      output = model(tokens, attn_mask, token_type_ids)\n",
        "  \n",
        "      loss = criterion(output, label)\n",
        "      prediction_list.extend((torch.sigmoid(output).cpu().detach().numpy() >= 0.5).astype(int).tolist())\n",
        "      label_list.extend(label.data.cpu().detach().numpy().astype(int).tolist())\n",
        "      total_loss += loss.item() \n",
        "\n",
        "    return label_list, prediction_list\n",
        "\n",
        "def train_and_evaluate(model, optimizer, train_dl, val_dl):\n",
        "  \"\"\"\n",
        "  train_and_evaluate function for the problem\n",
        "  Input:\n",
        "    model : torch.nn.Module (model that weill set in the hyperparameters (lstm, cnn etc.)\n",
        "    optimizer : Optimizer\n",
        "    train_dl : DataFrame (train dataframe)\n",
        "    val_dl : DataFrame (val dataframe)\n",
        "  Output:\n",
        "    model: model\n",
        "    label_best: list (true labels of the test data)\n",
        "    prediction_best: list (predicted labels of the test data)\n",
        "  \"\"\"\n",
        "  best_f = -999.9\n",
        "  scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
        "  for epoch in range(1, epoch_size+1):\n",
        "    total_loss = train(train_dl)\n",
        "    label_list, prediction_list = evaluate(model, val_dl)\n",
        "\n",
        "    f = f1_score(label_list, prediction_list, average='micro')\n",
        "    if f >= best_f:\n",
        "      patience = 0\n",
        "      best_epoch = epoch\n",
        "      best_f = f\n",
        "      print(\"save the model...\")\n",
        "      print(\"the current best f is %f\" % (best_f))\n",
        "      save_checkpoint({'epoch': epoch , 'state_dict': model.state_dict(), 'optim_dict': optimizer.state_dict()}, location=data_path + 'result')\n",
        "\n",
        "    else:\n",
        "        patience += 1\n",
        "\n",
        "    if patience > patience_all:\n",
        "        break\n",
        "\n",
        "    print(\"Epoch = \", epoch, \" train loss = \", total_loss) \n",
        "\n",
        "    scheduler.step()\n",
        "  return model, label_list, prediction_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bhy3TA5GAhlb",
        "outputId": "cbe52403-6b8d-4e6b-ae8b-01e4be915e5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at allenai/scibert_scivocab_cased were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(bert_model)\n",
        "embedding = BertModel.from_pretrained(bert_model,output_hidden_states = True).to(device)\n",
        "\n",
        "for param in embedding.parameters():\n",
        "   param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7Vy4cVFEg3F"
      },
      "outputs": [],
      "source": [
        "pretrained_model_name = \"bert\"\n",
        "model_path = \"allenai/scibert_scivocab_cased\" #\"bert-base-cased\"\n",
        "\n",
        "\n",
        "#model =  TextModel(embedding, hidden_size=100, out_n=6, m_type=\"lstm\", dropout=dropout).to(device)\n",
        "model = TransformerTextModel(embedding, 768, heads, n_hidden, n_layers, 6, dropout=dropout).to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=init_weight_decay)\n",
        "#criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "criterion = torch.nn.BCEWithLogitsLoss()\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKQ8nG0YAVJs"
      },
      "outputs": [],
      "source": [
        "train_dataset = pd.read_csv(data_path+\"dataset/train_2022.csv\")\n",
        "#val_dataset = pd.read_csv(data_path+\"dataset/val_2022.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5QwP02-FmRs"
      },
      "outputs": [],
      "source": [
        "train_dataset['target_list'] = train_dataset[['population', 'intervention', 'background', 'outcome', 'study design', 'other']].values.tolist()\n",
        "#val_dataset['target_list'] = val_dataset[['population', 'intervention', 'background', 'outcome', 'study design']].values.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w5MU_-tpPF7t"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_dataset_1, val_dataset = train_test_split(train_dataset, test_size=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5lsfeJJdEsb2"
      },
      "outputs": [],
      "source": [
        "dl_train = DataLoader(CustomDataset(train_dataset, tokenizer,  max_length), shuffle=True, num_workers=3, batch_size=batch_size)\n",
        "dl_val= DataLoader(CustomDataset(val_dataset, tokenizer,  max_length), shuffle=False, num_workers=3, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXjYUM79GSWZ",
        "outputId": "17c1db32-34c2-4db0-9fba-c30163de81ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "save the model...\n",
            "the current best f is 0.069899\n",
            "Epoch =  1  train loss =  0.07159443978031786\n",
            "save the model...\n",
            "the current best f is 0.254842\n",
            "Epoch =  2  train loss =  0.05946103439227848\n",
            "save the model...\n",
            "the current best f is 0.277666\n",
            "Epoch =  3  train loss =  0.05571258653694554\n",
            "save the model...\n",
            "the current best f is 0.279397\n",
            "Epoch =  4  train loss =  0.05368139466509977\n",
            "save the model...\n",
            "the current best f is 0.291127\n",
            "Epoch =  5  train loss =  0.0526219611835271\n",
            "save the model...\n",
            "the current best f is 0.322266\n",
            "Epoch =  6  train loss =  0.0519203371893803\n",
            "Epoch =  7  train loss =  0.0516083454966893\n",
            "save the model...\n",
            "the current best f is 0.355301\n",
            "Epoch =  8  train loss =  0.05141853038149121\n",
            "save the model...\n",
            "the current best f is 0.356530\n",
            "Epoch =  9  train loss =  0.05133574053732106\n",
            "Epoch =  10  train loss =  0.051345755501943806\n"
          ]
        }
      ],
      "source": [
        "model, label_list, prediction_list = train_and_evaluate(model, optimizer, dl_train, dl_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0WQVigBL1NL",
        "outputId": "3d181489-0833-4657-ae4f-9404acb44cde"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "filepath = os.path.join(data_path + 'result', 'best.pth.tar')\n",
        "model = TransformerTextModel(embedding, 768, heads, n_hidden, n_layers, 6, dropout=dropout).to(device)\n",
        "\n",
        "state_dict = load_checkpoint(filepath)\n",
        "model.load_state_dict(state_dict[\"state_dict\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ig4x_qSP_Mk"
      },
      "outputs": [],
      "source": [
        "test_dataset_new = pd.read_csv(data_path+\"dataset/test_2022.csv\")\n",
        "test_dataset_new['target_list'] = test_dataset_new[['population', 'intervention', 'background', 'outcome', 'study design', 'other']].values.tolist()\n",
        "test_dataset_new= DataLoader(CustomDataset(test_dataset_new, tokenizer,  max_length), shuffle=False, num_workers=3, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0p51fWrQGDX"
      },
      "outputs": [],
      "source": [
        "prediction_list = []\n",
        "label_list = []\n",
        "selected_sentences = []\n",
        "selected_id_list = []\n",
        "selected_id_sentence_list = []\n",
        "corrects = 0\n",
        "with torch.no_grad():\n",
        "  model.eval()\n",
        "  for batch in dl_train:\n",
        "    tokens, token_type_ids, attn_mask, label, selected_text, selected_id, selected_id_text = batch\n",
        "\n",
        "    label = label.to(device)\n",
        "    tokens, token_type_ids, attn_mask = tokens.to(device), token_type_ids.to(device), attn_mask.to(device)\n",
        "    output = model(tokens, attn_mask, token_type_ids)\n",
        "\n",
        "    loss = criterion(output, label)\n",
        "    prediction_list.extend(torch.sigmoid(output).cpu().detach().numpy().tolist())\n",
        "    label_list.extend(label.data.cpu().detach().numpy().astype(int).tolist())\n",
        "    selected_sentences.extend(selected_text)\n",
        "    selected_id_list.extend(selected_id.cpu().detach().numpy().astype(int).tolist())\n",
        "    selected_id_sentence_list.extend(selected_id_text.cpu().detach().numpy().astype(int).tolist())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e32QtI2pQMhB"
      },
      "outputs": [],
      "source": [
        "prediction_list = np.array(prediction_list)\n",
        "train_dl = pd.DataFrame({'Document' : selected_id_list, 'Sentence' : selected_id_sentence_list, 'population' : prediction_list[:,0],'intervention' : prediction_list[:,1],'background' : prediction_list[:,2],'outcome' : prediction_list[:,3],'study design' :prediction_list[:,4],'other':prediction_list[:,5], 'Text' :selected_sentences})\n",
        "train_dl.to_csv(data_path + \"answer_7518.csv\",index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6FKJoMxK5SOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IwAf0_i46m2F"
      },
      "outputs": [],
      "source": [
        "val_dataset_new = pd.read_csv(data_path+\"dataset/val_2022.csv\")\n",
        "val_dataset_new['target_list'] = val_dataset_new[['population', 'intervention', 'background', 'outcome', 'study design', 'other']].values.tolist()\n",
        "dl_val_new= DataLoader(CustomDataset(val_dataset_new, tokenizer,  max_length), shuffle=False, num_workers=3, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zWyvBARCRi3O"
      },
      "outputs": [],
      "source": [
        "prediction_list = []\n",
        "label_list = []\n",
        "selected_sentences = []\n",
        "selected_id_list = []\n",
        "selected_id_sentence_list = []\n",
        "corrects = 0\n",
        "with torch.no_grad():\n",
        "  model.eval()\n",
        "  for batch in dl_val_new:\n",
        "    tokens, token_type_ids, attn_mask, label, selected_text, selected_id, selected_id_text = batch\n",
        "\n",
        "    label = label.to(device)\n",
        "    tokens, token_type_ids, attn_mask = tokens.to(device), token_type_ids.to(device), attn_mask.to(device)\n",
        "    output = model(tokens, attn_mask, token_type_ids)\n",
        "\n",
        "    loss = criterion(output, label)\n",
        "    prediction_list.extend(torch.sigmoid(output).cpu().detach().numpy().tolist())\n",
        "    label_list.extend(label.data.cpu().detach().numpy().astype(int).tolist())\n",
        "    selected_sentences.extend(selected_text)\n",
        "    selected_id_list.extend(selected_id.cpu().detach().numpy().astype(int).tolist())\n",
        "    selected_id_sentence_list.extend(selected_id_text.cpu().detach().numpy().astype(int).tolist())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rjVMkdDHYLMh"
      },
      "outputs": [],
      "source": [
        "train_dl = pd.DataFrame({'Document' : selected_id_list, 'Sentence' : selected_id_sentence_list, 'population' : prediction_list[:,0],'intervention' : prediction_list[:,1],'background' : prediction_list[:,2],'outcome' : prediction_list[:,3],'study design' :prediction_list[:,4],'other':prediction_list[:,5], 'Text' :selected_sentences})\n",
        "train_dl.to_csv(data_path + \"answer_deneme.csv\",index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}